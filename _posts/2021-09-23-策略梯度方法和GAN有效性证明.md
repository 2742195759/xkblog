---
layout : post
title  : 策略梯度方法和GAN有效性证明
date   : 2021-09-23 13:00:00 +0000
category : scholar
typora-copy-images-to: ../../../code/xkblog/public/img/
typora-root-url: ../../../code
---

### Abstract

本文档主要如下三个方面的内容：

1. 推导策略梯度算法。
2. 推导GAN的有效性，即min max Game最后会收敛到真实的分布。
3. 推广，从GAN的证明回忆起了《NCE方法最终收敛到真实分布？》。并证明和阅读。
4. 上述两个知识如何在新的论文工作：Gan-Reweight中使用，以及如何按照真实数据和问题进行理论修改。

### 1. Police Gradient Algorithm (Simple Prove)

Police Gradient Algorithm can be referred in 《Introduction to Reinforcement Learning》. This algorithm mainly solves the problems in the following form: 

<span id='eq1'></span>
$$
\arg \max_{\theta} E_{x \sim p_\theta} [\ F(x)\ ]
$$
where F is a function of samples from distribution  $p_\theta$​ . 

It's a common sense using Monte Carlo algorithm to get the expectation. However after you sample a $x$​,  you can't derive $F(x)$ from $\theta$​ . 

Here come a question, why we need police gradient algorithm ? If you think deeper, you will find $F(x)$ can't derive from $\theta$​​ . So we need to expand the expectation and get derivative of $\theta$​ , then we get police gradient algorithm. 
$$
\nabla_\theta E_{x \sim p_\theta } [\ F(x)\ ] = \nabla_\theta \int_x F(x) p(x) = \int_x \nabla_\theta F(x) p(x) = \int_x F(x) \nabla_\theta  ln(p(x)) p(x) =  E_{x \sim p_\theta} [F(x) \nabla_\theta  ln(p(x)) ]
$$ {d}
Finally, if we expand the expectation, the gradient is also a expectation of $x$​​​. So we can use monte carlo algorithm to get the derivative. First we random select N examples of $x$​​​ and calculcate the derivative by  $\frac{1}{N} \sum_i F(x_i) \nabla_\theta \ln p(x_i)$​​​​  . 

The above method is called police gradient algorithm. This approach can solve problem in the [Eq1](#eq1) form . 

In the field of RL, $x$​​ is called action and $F(x)$​​​​ is  called rewards associated with action $x$​​​​​​ . Every step we take a action and try to maximize rewards, we will get the [Eq1](#eq1) . In this case, $p_\theta$ is the policy model, so we called policy gradient method.

### 2. effectiveness of Minmax game in GAN 