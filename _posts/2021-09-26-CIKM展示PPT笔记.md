---
layout : post
title  : CIKM展示PPT笔记
date   : 2021-09-26 13:00:00 +0000
category : scholar
typora-copy-images-to: ../../../code/xkblog/public/img/
typora-root-url: ../../../code
---

The 3 steps to present a paper is : 



1. Read the paper, and find what are the most exciting points / clever points.  
2. Explain why this method is the best way to solve this point / problem . 
3. Find the best way to get your audience to this point as quickly as possible . 



Repeat the above 3 steps until each point you want to present is presented.  



-----

Premise : 

1. Review-Based Recommandation.  Why Review ? 
2. Feature-aware recommendation : 

Main point / novelty of CIKM : 

#### 1 

1. the review information in realities can be highly sparse and imbalanced, which poses great challenges for effective user/item representations and satisfied performance enhancement. (The Problem is review information can be highly sparse and imbalanced, how to get effective representations and performance enhancement.  ->  counterfactually augmenting the training samples -> ) 
2. “what would be the user’s decision if her feature-level preference had been different?”.
3. constrained feature perturbation and frequency based sampling





-----

中文文稿： 

（P3）首先我们来介绍一下本论文的问题背景和动机。本论文建立在基于评论的推荐系统背景上。很多工作证实，评论信息的使用可以很好的提高推荐系统的性能。不仅仅直接使用评论信息，我们的方法细分而言属于Feature-aware recommendation。具体区别可以看下图。《解释图片》。 

（P4）虽然评论信息可以提供很多有价值的信息来帮助推荐，但是当推荐系统面领稀疏性的问题，如下图，我们可以看到所谓的交互矩阵是极端稀疏的，同时用户评论中的平均feature个数也是很低的。So，如何从极度稀疏的(u, i, f)三元组中有效挖掘出用户的爱好和物品的特征是当前Feature-Awared Recommendation面领的巨大难题。

（P5）：为了解决这个问题，我们提出利用CounterFactual Think对稀疏三元组(u,i,f) 进行数据增广。Counterfactual thinking is a recently emerged technique for enhancing the model performance and robustness.  It explores the use of alternative actions that are not taken by the agent, which may allow the model to operate better in data-scarce scenarios. 在推荐系统场景中，我们通过干预用户的兴趣，生成新的有效样本，最终达到缓解推荐问题固有的数据稀缺的问题。

（P6）：概括而言，我们的贡献主要包含如下几点：

1. We propose to improve review-based recommendation by augmenting the training samples based on the idea of counterfactual thinking
2. We design a learning-based intervention method to discover critical samples for better model optimization. Our proposed method can also provide recommendation explanations for user pair-wise preference.
3.  We theoretically analyze the relation between the number of generated training samples and the model prediction error, and design a simple but effective method to enhance the quality of the generated samples.
4. We conduct extensive experiments to evaluate our model’s effectiveness and also present intuitive examples to illustrate the recommendation explanations provided by our model

（P7）（CF 模型）--  Overview

这里我们先介绍我们模型的Overview。我们提出的《论文名字》主要包含3个步骤部分，首先是训练一个Feature-Aware推荐模型网络，负责对用户和商品对进行打分，这里被称为CF模型。第二步是一个CounterFactual数据增广策略，主要目的是利用训练好的CF模型对原始数据集进行数据增广。第三步是利用原始的数据和增广的数据对原始的CF模型进行Finetune。接下来我们将介绍CF模型的细节和我们提出的CounterFactual数据增广策略。

（P8）（CF 模型）--  recommendation part

这里我们先介绍我们模型的推荐网络细节。我们的模型主要目的是利用(u, i, f) 三元组计算出用户的兴趣向量和item的特征向量。计算的方法主要如下公式。然后通过user和item的向量获取最后的得分。因为我们提出的CF增广策略与推荐模型无光，为了证明我们方法的有效性，我们在对user兴趣向量和item的特征向量进行打分的时候实验了多种不同的g(x)函数，一共包括Attention、MLP、Elementwise Add、Elementwise Mul and Hybrid method。

（P9）（CF 模型）--  Counterfactual Data Argument Strategy

从CF模型中，我们已经对每个用户获取了一个兴趣向量，对每个item获取了一个特征向量。CounterFactual数据增广就是对用户的兴趣向量进行扰动，直到用户反转对正负样本的选择。如果很小的扰动就可以反转用户对正负样本的选择，说明这对正负样本本来就是hard样本，因此我们生成一对(u, i-, i+) 的样本对。上述过程建模为数学优化问题，就是如下的公示。

（P10）（CF模型） --  Feature Perturbation

通过对扰动添加不同的约束，我们有不同的增广方法，这里我们介绍Hard和Soft两种不同的约束。首先是Hard方法。Usually, people may only consider a small part of them in the decision process，所以我们对兴趣向量添加0/1约束，即我们只会对兴趣向量中的最大的K个进行扰动，其他的Tao都是0，表示下来就是如下形式。第二个是使用soft的约束，我们额外加入了一范数来获得稀疏的扰动向量。

（P11） 试验

最后是一些试验结果。





```mermaid
graph ; 
Train a Net
```









