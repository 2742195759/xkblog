---
layout : post
title  : pg实验1
date   : 2021-02-26 19:33:00 +0000
category : phraseground
typora-copy-images-to: ../../../code/xkblog/public/img/
typora-root-url: ../../../code
---

## 前置实验

本部分是前置实验之后的改进实验，只记录改进之后的部分。然后从MattNet开始。之前的实验结果见Mac: [PhraseGround.pptx](/xkblog/public/file/Phrase Ground.pptx)。

## 一. 使用FasterRcnn作为ProposalNet

之前一直使用的是 Cvpack2.ProposalNet作为ProposalNet提取网络，并且从中提取了1000个Proposals。但是参考了MattNet发现，使用FasterRCNN目标检测之后的PredBoxes作为ProposalNet是更好的，因此改进了一下。发现确实很不错。

#### 具体措施和实验代码：

实验代码在 cvpack2_model/phraseground/FasterRCNN 中。使用./start_train.sh 来运行模型并且在 ./log/proposal目录下生成向上兼容格式的Proposals。这些Proposals包含Classes关键字，存储了当前的框的 box + roi_pooled_feat + coco_class。这些信息可以用来直接实现MattNet网络。

同时实现了 FasterRCNN Proposals + SCRC + BinaryCrossEntropyLoss 的实验（实验1）。

#### 实验结果：

###### 实验结果：

<font color='green'>FaseterRCNN( 0.2 ) + SCRC + BinaryCrossEntropyLoss</font>

| acc@1 | acc@5 | acc@10 | acc@1000 |
| :---: | :---: | :----: | :------: |
| 0.500 | 0.846 | 0.878  |  0.884   |

<font color='orange'>ProposalNet( 1000 ) + SCRC + Max-Margin</font>

| acc@1 | acc@5 | acc@10 | acc@1000 |
| :---: | :---: | :----: | :------: |
| 0.187 | 0.472 | 0.622  |  1.000   |

###### 其他指标：

1. 1卡： 运行时间 30 epoch 需要22h ; 1 epoch 大约 40 min。
2. Proposals覆盖度： 大约为 85% - 89%

###### 演示截图：

<img src="/xkblog/public/img/截屏2021-02-26 下午8.24.24.png" alt="截屏2021-02-26 下午8.24.24" style="zoom:50%;" />

#### 实验总结

最后的总结就是：使用FasterRCNN确实更加好。相当于我们第一部分已经筛选掉了很多不合格的Proposals。尤其是对refcoco数据集来说，因为我们的FasterRCNN就是在coco数据集上进行训练的，所以可以得到更好的结果，可以命中更多的物体。但是带来的不好的点就是，如何权衡 覆盖率 和 筛选。

#### 下一步实验：

1. 通过减少数据加载时间来减少运行速度： 问题应该在ImageLoad的过程中，改进方法是不使用原来的raw image，只使用ProposalNet提取的feature来加速。<font color='red'>可能需要自己重写 Boxes 的放缩变化。</font>(Doing)
2. 逐渐融入 MattNet 中的实现。增加Image和Semantic的联系。而不是使用简单的SCRC双塔模型。下一步，检测Attribute Predict是否有效。
3. 添加训练中融入 GT Boxes 的逻辑。因为训练过程中引入GT可以矫正由于Proposal不准导致的偏差，至少可以纠正训练过程中可能出现的ProposalBias。

## ReferitFast 数据集

#### 实现细节

为了解决[上述第一个问题](#下一步实验)，开发了ReferitFast数据集。这个数据集主要是为了提高MattNet的速度，因此不兼容其他的代码。但是由于重写了文件，所以不妨碍原来的代码使用referit数据集。

ReferitFastDataset 主要有以下不同：

1. 删除了很多图像内容相关的关键字。例如不进行图片读取，不进行图像的Transform。因为这些操作需要的时间很多，但是在最后的MattNet中却不会用到。所以建议将图像处理放到预处理中完成，然后DatasetLoader只负责文件读取。添加了only_apply_box(transformer, annotations) 函数，用来只对 prop_boxes 和 gt_boxes 进行放缩，而不处理图像内容。
2. 默认开启 hdf5 读取模式，但是这个模式其实加速不大。所以可以默认关闭。
3. 测试通过，不改变原来的逻辑。

主要的处理 Boxes 变换的函数是如下的函数，这里记录以供参考：

```python
def only_apply_box(transformer, annotations):
    for annotation in annotations:
        if "bbox" in annotation:
            bbox = annotation['bbox']
            annotation["bbox"] = transformer.apply_box(bbox)[0]
            annotation["bbox_mode"] = BoxMode.XYXY_ABS

...
only_apply_box(ScaleTransform(dd['height'], dd['width'], 224, 224), dd['annotations'])
```

注意数据集选择使用如下配置代码： 

```python
# config.py 文件中
    DATASETS=dict(
        DATA_ROOT="/home/data/dataset", 
        TRAIN=("referitfast_refcoco_unc_train", ),
        TEST=("referitfast_refcoco_unc_val", ),
        IMAGE_ONLY=False, 
        #TEST=("referit_refclef_unc_train", ),
        EVAL_TYPE="phrasegrounding", 
        PHRASE_GROUNDING=dict(
            TRAIN_PROPOSAL_ROOT="/home/data/Output/FasterRCNN/proposal-0.2-train", 
            TEST_PROPOSAL_ROOT="/home/data/Output/FasterRCNN/proposal-0.2-val", 
        ),
    ),
```

⚠️： 以后的所有改动都基于 referitfast。主要是为了训练速度。所以referit 已经被淘汰了，以后尽量少用，只做为代码范例参考。

#### 实验结果：

<font color='green'>训练时间： 50min -> 14min</font>

<font color='green'>测试时间： 20min -> 3min</font>

