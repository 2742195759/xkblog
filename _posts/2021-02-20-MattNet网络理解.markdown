---
layout : post
title  : MattNet 网络理解
date   : 2021-02-20 5:33:00 +0000
category : DL
typora-copy-images-to: ../../../code/xkblog/public/img/
typora-root-url: ../../../code
---

#### 当前难点：

1. 需要高阶和低阶语义信息： 如何在ProposalNet 网络中添加C3和C4两个阶段的特征？？修改ProposalNet网络吗？
2. 需要找到FasterRCNN中同类物体的所有信息： 如何在ProposalNet中找到对应物体的框？？需要提前熟悉一下FasterRCNN
3. **<font color='red'>Attribute Predict 模块:</font> 看他的实现，好像可以直接加入这个模块。（这个模块可以作为图卷积模块的创新点）**
4. **<font color='red'>引入Transformer: </font> 原来的论文使用的是普通的Attention网络和LSTM。尝试引入Transformer作为创新点**

#### 当前研究点：

1. 数据集中加入 Attribute Predict 模块支持。
2. SCRC 中加入 Attribute Predict 模块 -- 查看这个模块是否可以改善原来的 SCRC 模型，消融分析。得到结果如果效果好，加入到 GraphRefer 模型中。

#### <font color='green'> 对Attribute Predict的研究：</font>

``` 
# 下面是对 parse.json 文件的[0]的输出 len() == 100
{
  'tokens': ['the', 'lady', 'with', 'the', 'blue', 'shirt'], 
 	'raw': 'THE LADY WITH THE BLUE SHIRT',  
  'sent_id': 0, 
  'sent': 'the lady with the blue shirt',
  'parse': {'parsetree': '(ROOT (NP (NP (DT the) (NN lady)) (PP (IN with) (NP (DT the) (JJ blue) (NN shirt)))))', 'text': 'the lady with the blue shirt', 'dependencies': [['root', 'ROOT', 'lady'], ['det', 'lady', 'the'], ['det', 'shirt', 'the'], ['amod', 'shirt', 'blue'], ['prep_with', 'lady', 'shirt']], 'indexeddependencies': [['root', 'ROOT-0', 'lady-2'], ['det', 'lady-2', 'the-1'], ['det', 'shirt-6', 'the-4'], ['amod', 'shirt-6', 'blue-5'], ['prep_with', 'lady-2', 'shirt-6']], 'words': [['the', {'NamedEntityTag': 'O', 'CharacterOffsetEnd': '3', 'Lemma': 'the', 'PartOfSpeech': 'DT', 'CharacterOffsetBegin': '0'}], ['lady', {'NamedEntityTag': 'O', 'CharacterOffsetEnd': '8', 'Lemma': 'lady', 'PartOfSpeech': 'NN', 'CharacterOffsetBegin': '4'}], ['with', {'NamedEntityTag': 'O', 'CharacterOffsetEnd': '13', 'Lemma': 'with', 'PartOfSpeech': 'IN', 'CharacterOffsetBegin': '9'}], ['the', {'NamedEntityTag': 'O', 'CharacterOffsetEnd': '17', 'Lemma': 'the', 'PartOfSpeech': 'DT', 'CharacterOffsetBegin': '14'}], ['blue', {'NamedEntityTag': 'O', 'CharacterOffsetEnd': '22', 'Lemma': 'blue', 'PartOfSpeech': 'JJ', 'CharacterOffsetBegin': '18'}], ['shirt', {'NamedEntityTag': 'O', 'CharacterOffsetEnd': '28', 'Lemma': 'shirt', 'PartOfSpeech': 'NN', 'CharacterOffsetBegin': '23'}]]}
}
```

```
# 下面是对 refer-parser2/cache/parsed_atts/refcoco_unc/sents.json 文件
# 的json[0]['atts'] 的输出. len(json) == 142210
{
	'r4': ['none'], 
	'r5': ['prep_with'], 
	'r6': ['shirt'], 
	'r7': ['none'], 
	'r1': ['lady'], 
	'r2': ['none'], 
	'r3': ['none'], 
	'r8': ['blue']
}
```

可以看到，parse.word = [[...],[...]]很重要，然后JJ DT NN IN等是语法词汇，可以见链接： [PartOfSpeech](https://blog.csdn.net/LYJXCZ/article/details/17082341)  其中有各种名词表示的含义。例如JJ表示名词形容词，这个可以作为 attribute 的关键。

其次，在refer-parser 中应用了一个template parser的工具，见论文中引用[13]。这个工具的接受parse.json中的格式，输出sents.json格式，然后其中的不同的r1 - r8 的关系是如下：我们可以直接使用atts 中的信息的某一些作为 attribute tag。同时插入到我们xkcv2的 referit.dataset 中。下面是r1 - r8 原文的解释

> ##### from refer-parser
>
>Specifically, r1 = entry-level name, r2 = color, r3 = size, r4 = abs. location,
>r5 = rel. location, r6 = rel. object, r7 = generic, r8 = the left words

**在 MattNet文章中提到，我们使用 color and generic attribute with low-frequency words removed 来作为 attribute 。其实也就是 r1 和 r7 作为attribute关键词，然后过滤低频名词。注意加上Balanced Strategy。<font color='orange'>其实作为尝试，我们可以直接过滤 JJ 和 NN 来作为关键词，因为 r2 中感觉很多颜色名词都没有被搜集（虽然可能是名词不直接形容主体）</font>**

##### Code + 具体实现 + 解析：

在论文中，对Attribute Predict 分支的描述是下图的左边部分：

<div align='center'><img src="/xkblog/public/img/截屏2021-02-24 下午5.48.52.png" alt="截屏2021-02-24 下午5.48.52" style="zoom:50%;" /></div>

代码中，对于Attribute Prediction过程中，其中使用的是Resnet fc7(n, 2048, 7, 7) 和 pool5(n, 1024, 7, 7) 两个层次的信息。分别对应的就是上面的两个blob，然后使用 1x1 的卷机操作。最后的 avg.pooling 应该是 Global Average Pooling。而GAP和AP其实本质相同，唯一的不同是窗口的大小，GAP是窗口大小是Feature Map大小的AP。

```python
att_feats = self.att_fuse(torch.cat([pool5, fc7], 1))   # n x 49 x 512
# self.att_fuse 是全连接 + BatchNorm + ReLU
avg_att_feats = att_feats.view(batch, -1, 512).mean(1)  # n x 512
avg_att_feats = nn.Dropout(0.3)(avg_att_feats)   # 在加上一层 Dropout
att_scores = self.att_fc(avg_att_feats)    # output. # n x num_att
```

```mermaid
graph LR
	A[<font color='red'>Feature</font>] --> B[FC] --> C[BatchNorm] --> D(ReLU) --> E[Dropout] --> F(FC) --> G(<font color='red'>Score</font>)
	
```

#### MaskRCNN 特征提取过程（放弃）

[github 库地址](https://github.com/lichengunc/MAttNet)：这个库是MattNet的库地址，决定使用他的预处理方法来进行预处理。然后更改自己的ReferitDataset从这个数据集读取数据。将自己的模型分为2个部分，一个是Preprocess，一个是Training，一个是Inference。然后使用预先训练好的 mrcn 模型来进行特征提取。提取之后存储入h5文件。然后在Referit 数据集合中只需要使用基本的读取操作即可。通过这个方法，我们可以将 Referit 的数据集处理分离，专注 训练部分。 

⚠️：教训得到，使用别人的预处理绝对比自己从头写好！！尤其是使用了别的模型作为预处理。除非是很简单的DataLoader比如推荐系统的陈博的。我们的 模型文件夹 只需要负责加入预处理脚本，同时对数据进行重新封装一下即可。新建一个DataLoader 名为 ReferitMrcn 来进行MattNet的开发。

⚠️：我的看法改变了。各种bug我真的是烦死了。果然只要有C++就会有bug。果然还是docker好啊。安装啥的太麻烦了。但是运行不了docker啊

⚠️：我放弃了，安装这个MaskRCNN真的是有毒一样。为什么他们用的版本那么老。就各种出问题。我直接在自己的Cvpack2里面实现吧。Cvpack2至少安装没啥问题了。我看懂提取的特征，然后使用FasterRCNN模拟吧。MaskRCNN再说吧。

#### Cvpack2  Resnet  输出 Head Feature ： 1 x 1024 x H x W 

接下来我们研究 Cvpack2中的Resnet如何提取出 mrcn 中需要的 Head Feature。其实也就是 ROI Pooling 前的feature，格式是 1 x 1024 x H x W 。应该在 ProposalNet中可以得到

###### torch.nn.AdaptiveAvgPool2d((H, W)) ： 

- 这个函数很有趣，以后AvgPool2D就用这个代替，其中H,W是所需要的输出，然后会自动给你设置Kernel 和 Stride。如果H=W=1 ，表示GlobalAveragePooling。

##### Cvpack2 Backbone 

文件夹：cvpack2/modeling/backbone/ 文件夹下

```pseudocode
class Backbone : 
- forward
- output_shape (输出self._output_features中name对应的)
	例如： 

>>> self.backbone.bottom_up.output_shape()
{'res2': ShapeSpec(channels=256, height=None, width=None, stride=4), 'res3': ShapeSpec(channels=512, height=None, width=None, stride=8), 'res4': ShapeSpec(channels=1024, height=None, width=None, stride=16), 'res5': ShapeSpec(channels=2048, height=None, width=None, stride=32)}
```

```pseudocode
class ResNet : 
		源文件:cvpack2/modeling/backbone/resnet.py
```

###### 更改 ResNet 的配置常用: 

```python
# 更改输出的层 
# 可以是 stem | res2(256) | res3(512) | res4(也就是head: 1024) | res5(2048) | linear
# 然后一些展示: 
out_features = cfg.MODEL.RESNETS.OUT_FEATURES 

# 更改输出类
num_classes = cfg.MODEL.RESNETS.NUM_CLASSES   
```

###### 创建ResNet方法：

```python
# Example from cvpack2/modeling/backbone/fpn.py
from .resnet import build_resnet_backbone 
bottom_up = build_resnet_backbone(cfg, input_shape)
```

###### Pytorch 的 ResNet 实现部分代码

```python
def forward(self, x):
    x = self.conv1(x)  # stem

    x = self.layer1(x) # res2
    x = self.layer2(x) # res3
    x = self.layer3(x) # res4
    x = self.layer4(x) # res5

    x = self.avgpool(x)# pool5
    x = x.view(x.size(0), -1)
    x = self.fc(x)     # linear
    return x

```

##### Cvpack2 RCNN 类



###### Cvpack2 RCNN 类的结构:

见文件 cvpack2/modeling/meta_arch/rcnn.py : GeneralizedRCNN，其中包含3个大体抽象步骤：

1. Per-image feature extraction (aka backbone : 见上一节)
2. Region proposal generation (proposal_generator :  同目录下proposal_generator文件夹)
3. Per-region feature extraction and prediction (roi_heads :  同目录下 roi_heads 文件夹)

然后他们的流程图是： 

```mermaid
graph TD
self.process_image --image--> self.backbone --featmap--> self.proposal_generator --per region-->self.roi_heads --"output"--> 结束
```

###### RCNN : roi_head

roi_head 目录：cvpack2/modeling/roi_heads 。 这个部分主要的目的是将 Proposals 和 FeatureMap 作为输入，然后进行 per-proposal 的不同任务的输出。基类是 class ROIHeads。

roi_head 内部有很多的变种和一些辅助类。其中最重要的是StandardROIHeads。这个类被很多meta arch使用。主要的抽象思想就是：Feature 和 Transform 在不同的task之间不共享，现在实现中包含3种Mask / Boxes / Keypoint任务。

⚠️： 需要开启Mask任务，只需要在 cfg.MODEL.MASK_ON = True ;  Box任务是默认开启的。

```python
# StandardROIHeads 的 Box 任务
class StandardROIHeads(ROIHeads):
    def __init__(self, cfg, input_shape):
        super(StandardROIHeads, self).__init__(cfg, input_shape)
        self._init_box_head(cfg)  # 需要提供 cfg.build_box_head()
        self._init_mask_head(cfg)
        self._init_keypoint_head(cfg)
        
    def _init_box_head(self, cfg):
        # fmt: off
        pooler_resolution        = cfg.MODEL.ROI_BOX_HEAD.POOLER_RESOLUTION
        pooler_scales            = tuple(1.0 / self.feature_strides[k] for k in self.in_features)
        sampling_ratio           = cfg.MODEL.ROI_BOX_HEAD.POOLER_SAMPLING_RATIO
        pooler_type              = cfg.MODEL.ROI_BOX_HEAD.POOLER_TYPE
        self.train_on_pred_boxes = cfg.MODEL.ROI_BOX_HEAD.TRAIN_ON_PRED_BOXES
        # fmt: on

        # If StandardROIHeads is applied on multiple feature maps (as in FPN),
        # then we share the same predictors and therefore the channel counts must be the same
        in_channels = [self.feature_channels[f] for f in self.in_features]
        # Check all channel counts are equal
        assert len(set(in_channels)) == 1, in_channels
        in_channels = in_channels[0]

        self.box_pooler = ROIPooler(
            output_size=pooler_resolution,
            scales=pooler_scales,
            sampling_ratio=sampling_ratio,
            pooler_type=pooler_type,
        )
        # Here we split "box head" and "box predictor", which is mainly due to historical reasons.
        # They are used together so the "box predictor" layers should be part of the "box head".
        # New subclasses of ROIHeads do not need "box predictor"s.
        self.box_head = cfg.build_box_head(
            cfg, ShapeSpec(channels=in_channels, height=pooler_resolution, width=pooler_resolution)
        )
        self.box_predictor = FastRCNNOutputLayers(
            self.box_head.output_size, self.num_classes, self.cls_agnostic_bbox_reg
        )
      
    def _forward_box(
        self, features: List[torch.Tensor], proposals: List[Instances]
    ) -> Union[Dict[str, torch.Tensor], List[Instances]]:
        """
        Forward logic of the box prediction branch. If `self.train_on_pred_boxes is True`,
            the function puts predicted boxes in the `proposal_boxes` field of `proposals` argument.

        Args:
            features (list[Tensor]): #level input features for box prediction
            proposals (list[Instances]): the per-image object proposals with
                their matching ground truth.
                Each has fields "proposal_boxes", and "objectness_logits",
                "gt_classes", "gt_boxes".

        Returns:
            In training, a dict of losses.
            In inference, a list of `Instances`, the predicted instances.
        """
        box_features = self.box_pooler(features, [x.proposal_boxes for x in proposals])
        box_features = self.box_head(box_features)
        pred_class_logits, pred_proposal_deltas = self.box_predictor(box_features)
        del box_features

        outputs = FastRCNNOutputs(
            self.box2box_transform,
            pred_class_logits,
            pred_proposal_deltas,
            proposals,
            self.smooth_l1_beta,
        )
        if self.training:
            if self.train_on_pred_boxes:
                with torch.no_grad():
                    pred_boxes = outputs.predict_boxes_for_gt_classes()
                    for proposals_per_image, pred_boxes_per_image in zip(proposals, pred_boxes):
                        proposals_per_image.proposal_boxes = Boxes(pred_boxes_per_image)
            return outputs.losses()
        else:
            pred_instances, _ = outputs.inference(
                self.test_score_thresh, self.test_nms_thresh, self.test_detections_per_img
            )
            return pred_instances
```

roi_heads 中的任务几乎都是使用 ROIPooler 进行PerBoxes特征提取。然后 \_forward\_XXX 作为任务计算。forward中会使用Output类：FastRCNNOutputs。这些Output类负责搜集计算Loss和Inference。

```mermaid
graph LR
A[StandardROIHeads] ---- B[Box任务]
A ---- C[Mask任务]
A ---- D[Keypoint任务]

B ---- B1[self.box_pooler]
B ---- B2[self.box_head]
B ---- B3[output用于计算Losses和inference]

C ---- C1[...]
D ---- D1[...]
```

###### 为 ProposalNet 添加 category_id 关键字

由于 MattNet 需要寻找不同的Proposal的类别信息，所以直接使用ProposalNet判断有没有objectness 是不够的。需要使用FasterRCNN网络的预测头来进行处理。

<font color='red'> Task1: 运行预训练好的 cvpack2.FasterRCNN 在图片上进行inference，展示目标检测结果(Todo) </font>

Generated

